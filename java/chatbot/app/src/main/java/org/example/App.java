/*
 * This source file was generated by the Gradle 'init' task
 */
package org.example;

import com.openlayer.api.client.OpenlayerClient;
import com.openlayer.api.client.okhttp.OpenlayerOkHttpClient;
import com.openlayer.api.models.InferencePipelineDataStreamParams;
import com.openlayer.api.models.InferencePipelineDataStreamResponse;

import java.util.List;
import javax.json.Json;

public class App {
    public static void main(String[] args) {
        // Configure the client using environment variables
        // OpenlayerClient client = OpenlayerOkHttpClient.fromEnv();

        // Or you can configure the client with additional properties
        /*
         * OpenlayerClient client = OpenlayerOkHttpClient.builder()
         * .fromEnv()
         * // Additional properties can be set here
         * .build();
         */

        OpenlayerClient client = OpenlayerOkHttpClient.builder()
                .fromEnv()
                .apiKey("qRVcoWO49HRy7Q1qhywgzCN9IrS5sPwH")
                .baseUrl("http://localhost:8080/v1")
                .build();

        // Replace with your inference pipeline id
        String inferencePipelineId = "51ed4ba8-c7b3-4cb7-8433-314b3721343b";

        // Let's say we want to stream the following row, which represents a model
        // prediction:
        // Define a row with the relevant fields
        InferencePipelineDataStreamParams.Row row = InferencePipelineDataStreamParams.Row.builder()
                .putAdditionalProperty("user_query", Json.createValue("what's the meaning of life?"))
                .putAdditionalProperty("output", Json.createValue("42"))
                .putAdditionalProperty("tokens", Json.createValue(7))
                .putAdditionalProperty("cost", Json.createValue(0.02))
                .putAdditionalProperty("timestamp", Json.createValue(1620000000))
                .build();

        // Create Inference Pipeline Data Stream Parameters
        InferencePipelineDataStreamParams params = InferencePipelineDataStreamParams.builder()
                .inferencePipelineId(inferencePipelineId)
                .rows(List.of(row))
                .config(InferencePipelineDataStreamParams.Config
                        .ofLlmData(InferencePipelineDataStreamParams.Config.LlmData.builder()
                                .outputColumnName("output")
                                .costColumnName("cost")
                                .inputVariableNames(List.of("user_query"))
                                .numOfTokenColumnName("tokens")
                                .timestampColumnName("timestamp")
                                .build()))
                .build();

        // Execute the request
        InferencePipelineDataStreamResponse inferencePipelineDataStreamResponse = client.inferencePipelines().data()
                .stream(params);

        // Print the response
        System.out.println(inferencePipelineDataStreamResponse);
    }
}
